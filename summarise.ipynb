{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\python 311\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\python 311\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\python 311\\lib\\site-packages (from pytesseract) (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\python 311\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\python 311\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\python 311\\lib\\site-packages (from pytesseract) (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: Bounding box (476.4, 836.2099999999999, 566.4, 875.2099999999999) is not fully within parent page bounding box (0, 0.0, 595.32, 841.92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python 311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Your max_length is set to 150, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the PDF:\n",
      "Prajna AI hackathon challenge focuses on building acomprehensive PDF ingestion and querying system that allows users to upload PDF documents. The solution should feature an intuitive, interactive frontend and be deployable in a cloud environment. Detailed Requirements and Criteria:. PDF Document Ingestion10 MARKS. User Querying Interface: Allow users to submit natural language queries against the PDF. Citation and Validation: Provide citations for the information returned in response to userqueries. Interactive Frontend: Design a user-friendly web interface for document interaction. 2. Embedding Generation and Data Persistence: Use a state-of-the-art model to generate embeddings that capture the semantics of the ARTICLEPDF content. 3. Question Suggestion Engine: Develop an engine that generates 3-5 insightful questions related to the uploaded ARTICLEPDFâ€™s content. 4. User Querying Interface: Create a responsive interface that allows users to submit natural language queries. Citation and Validation: For each answer generated in response to a user query, provide a citation that indicates the source within the PDF. Frontend: Build an intuitive, user-friendly web interface that facilitates document uploads, question suggestions, and query entry. Systems should be deployed on a cloud platform with considerations for reliability, reliability, and accessibility. Ensure users can access the system through a public URL with minimalowntime and fast response times. Support additional document formats like HTML or spreadsheets to enhance the versatility of the system. 3. Customizable User Dashboard: Create a customizable dashboard where users can manage their uploaded documents, view query history, and access frequently asked questions. For inspiration and guidance on implementing document querying systems,consider examining Notebook LM by Google.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import pipeline\n",
    "\n",
    "# Function to extract text from the PDF, including text from images and tables\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_num]\n",
    "            # Extract regular text\n",
    "            pdf_text += page.extract_text() or \"\"\n",
    "            \n",
    "            # Extract tables and add to the text\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                pdf_text += \"\\n\" + \" | \".join([\" | \".join(row) for row in table if row]) + \"\\n\"\n",
    "            \n",
    "            # Extract images and run OCR\n",
    "            for img in page.images:\n",
    "                try:\n",
    "                    # Get the image as a byte array\n",
    "                    x0, top, x1, bottom = img['x0'], img['top'], img['x1'], img['bottom']\n",
    "                    image = page.within_bbox((x0, top, x1, bottom)).to_image()\n",
    "\n",
    "                    # Extract the original image as a PIL image\n",
    "                    pil_image = image.original\n",
    "                    \n",
    "                    # Convert PIL Image to bytes and apply OCR\n",
    "                    img_byte_arr = BytesIO()\n",
    "                    pil_image.save(img_byte_arr, format='PNG')  # Save to bytes\n",
    "                    img_byte_arr.seek(0)  # Move to the beginning of the BytesIO buffer\n",
    "                    ocr_text = pytesseract.image_to_string(Image.open(img_byte_arr))\n",
    "                    pdf_text += \"\\n[Image Text]: \" + ocr_text + \"\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image: {e}\")\n",
    "    return pdf_text\n",
    "\n",
    "# Function to summarize long text in chunks\n",
    "def summarize_long_text(text, chunk_size=1000, max_length=150, min_length=50):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    # Split text into chunks of chunk_size\n",
    "    text_chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    \n",
    "    # Summarize each chunk\n",
    "    summaries = []\n",
    "    for chunk in text_chunks:\n",
    "        # Adjust max_length dynamically\n",
    "        input_length = len(chunk)\n",
    "        adjusted_max_length = min(max_length, input_length // 2)\n",
    "        summary = summarizer(chunk, max_length=adjusted_max_length, min_length=min_length, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    \n",
    "    # Combine summaries\n",
    "    full_summary = \" \".join(summaries)\n",
    "    return full_summary\n",
    "\n",
    "# Main function to extract and summarize the PDF content\n",
    "def summarize_pdf(pdf_path, chunk_size=1000, max_length=150, min_length=50):\n",
    "    # Step 1: Extract text, tables, and images (with OCR) from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Step 2: Summarize the extracted content\n",
    "    summary = summarize_long_text(pdf_text, chunk_size=chunk_size, max_length=max_length, min_length=min_length)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Provide the path to your PDF\n",
    "pdf_path = \"C:/Users/nisht/OneDrive/Desktop/default Project/Problem Statement.pdf\" # Adjust this if the file is not in the same directory\n",
    "summary = summarize_pdf(pdf_path, chunk_size=1000, max_length=150, min_length=50)\n",
    "print(\"Summary of the PDF:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
